{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column headings:\n",
      "Index(['Subject', 'Language', 'Gender', 'Age', 'Vocabulary', 'Author Task',\n",
      "       'Overall English Likeness', 'Task', 'PercentCorrect', 'Q1', 'Q2', 'Q3',\n",
      "       'Q4', 'Q5', 'Average English Likeness'],\n",
      "      dtype='object')\n",
      "    Subject Language  Gender  Age  Vocabulary  Author Task  \\\n",
      "0     a_001  English  Female   21       102.0          NaN   \n",
      "1     a_002  English  Female   19        98.0         -9.0   \n",
      "2     a_003  English    Male   19        92.0         -4.0   \n",
      "3     a_004  English  Female   19       115.0         12.0   \n",
      "4     a_005  English  Female   21       102.0         19.0   \n",
      "5     a_006  English  Female   21       102.0         14.0   \n",
      "6     a_007  English    Male   19       133.0          4.0   \n",
      "7     a_008  English  Female   21        96.0          8.0   \n",
      "8     a_009  English  Female   20       114.0          3.0   \n",
      "9     a_010  English  Female   20       103.0          1.0   \n",
      "10    a_011  English  Female   20        97.0          2.0   \n",
      "11    a_012  English  Female   21        96.0         10.0   \n",
      "12    a_013  English  Female   18       110.0          9.0   \n",
      "13    a_014  English  Female   21       119.0         18.0   \n",
      "14    a_015  English  Female   22       113.0         11.0   \n",
      "15    a_016  English    Male   19       127.0          6.0   \n",
      "16    a_017  English  Female   20       120.0          5.0   \n",
      "17    a_019  English  Female   30       114.0         23.0   \n",
      "18    a_020  English  Female   20       126.0         20.0   \n",
      "19    a_021  English  Female   21       113.0         12.0   \n",
      "20    a_022  English  Female   21       131.0         32.0   \n",
      "21    a_023  English  Female   18       116.0         23.0   \n",
      "22    a_024  English  Female   19       115.0         17.0   \n",
      "23    a_025  English  Female   19         NaN         18.0   \n",
      "24    a_026  English  Female   21         NaN         20.0   \n",
      "25    a_027  English    Male   26        88.0         -7.0   \n",
      "26    a_028  English  Female   37        79.0          6.0   \n",
      "27    a_029  English  Female   20       114.0         14.0   \n",
      "28    a_030  English  Female   20        91.0          4.0   \n",
      "29    a_031  English    Male   35       107.0          2.0   \n",
      "..      ...      ...     ...  ...         ...          ...   \n",
      "192     129   Hebrew  Female   24         NaN          NaN   \n",
      "193     130   Hebrew  Female   23         NaN          NaN   \n",
      "194     131   Hebrew  Female   23         NaN          NaN   \n",
      "195     133   Hebrew  Female   21         NaN          NaN   \n",
      "196     134   Hebrew    Male   25         NaN          NaN   \n",
      "197     135   Hebrew  Female   23         NaN          NaN   \n",
      "198     136   Hebrew  Female   23         NaN          NaN   \n",
      "199     137   Hebrew  Female   23         NaN          NaN   \n",
      "200     138   Hebrew    Male   24         NaN          NaN   \n",
      "201     139   Hebrew  Female   23         NaN          NaN   \n",
      "202     141   Hebrew    Male   24         NaN          NaN   \n",
      "203     142   Hebrew  Female   21         NaN          NaN   \n",
      "204     145   Hebrew    Male   23         NaN          NaN   \n",
      "205     146   Hebrew  Female   22         NaN          NaN   \n",
      "206     148   Hebrew  Female   24         NaN          NaN   \n",
      "207     149   Hebrew  Female   25         NaN          NaN   \n",
      "208     150   Hebrew  Female   23         NaN          NaN   \n",
      "209     152   Hebrew  Female   20         NaN          NaN   \n",
      "210     153   Hebrew  Female   22         NaN          NaN   \n",
      "211     154   Hebrew    Male   25         NaN          NaN   \n",
      "212     155   Hebrew  Female   22         NaN          NaN   \n",
      "213     156   Hebrew  Female   19         NaN          NaN   \n",
      "214     157   Hebrew  Female   25         NaN          NaN   \n",
      "215     159   Hebrew    Male   24         NaN          NaN   \n",
      "216     160   Hebrew  Female   22         NaN          NaN   \n",
      "217     161   Hebrew    Male   22         NaN          NaN   \n",
      "218     162   Hebrew  Female   25         NaN          NaN   \n",
      "219     164   Hebrew  Female   21         NaN          NaN   \n",
      "220     165   Hebrew    Male   24         NaN          NaN   \n",
      "221     166   Hebrew  Female   25         NaN          NaN   \n",
      "\n",
      "     Overall English Likeness            Task  PercentCorrect   Q1   Q2   Q3  \\\n",
      "0                         1.0      Linguistic            56.0  1.0  1.0  1.0   \n",
      "1                         NaN      Linguistic             NaN  NaN  NaN  NaN   \n",
      "2                         1.0      Linguistic            44.0  2.0  1.0  2.0   \n",
      "3                         0.0      Linguistic            76.0  1.0  1.0  1.0   \n",
      "4                         4.0      Linguistic            76.0  4.0  2.0  2.0   \n",
      "5                         2.0      Linguistic            60.0  1.0  1.0  2.0   \n",
      "6                         1.0      Linguistic            64.0  1.0  0.0  0.0   \n",
      "7                         3.0      Linguistic            76.0  2.0  2.0  2.0   \n",
      "8                         0.0      Linguistic            60.0  2.0  2.0  1.0   \n",
      "9                         2.0      Linguistic            48.0  4.0  2.0  1.0   \n",
      "10                        1.0      Linguistic            36.0  1.0  2.0  0.0   \n",
      "11                        1.0      Linguistic            56.0  1.0  1.0  0.0   \n",
      "12                        0.0      Linguistic            44.0  0.0  0.0  0.0   \n",
      "13                        1.0      Linguistic            52.0  1.0  1.0  4.0   \n",
      "14                        0.0      Linguistic            56.0  1.0  1.0  2.0   \n",
      "15                        2.0      Linguistic            68.0  2.0  3.0  2.0   \n",
      "16                        1.0      Linguistic            48.0  2.0  2.0  4.0   \n",
      "17                        1.0      Linguistic            52.0  2.0  2.0  1.0   \n",
      "18                        3.0      Linguistic            60.0  1.0  3.0  2.0   \n",
      "19                        1.0      Linguistic            44.0  1.0  0.0  0.0   \n",
      "20                        1.0      Linguistic            68.0  2.0  1.0  0.0   \n",
      "21                        1.0      Linguistic            56.0  0.0  1.0  1.0   \n",
      "22                        1.0      Linguistic            64.0  1.0  0.0  0.0   \n",
      "23                        1.0      Linguistic            64.0  0.0  0.0  0.0   \n",
      "24                        4.0      Linguistic            80.0  1.0  2.0  4.0   \n",
      "25                        0.0      Linguistic            28.0  1.0  1.0  2.0   \n",
      "26                        0.0      Linguistic            40.0  0.0  0.0  0.0   \n",
      "27                        2.0      Linguistic            60.0  2.0  1.0  1.0   \n",
      "28                        2.0      Linguistic            48.0  2.0  0.0  2.0   \n",
      "29                        1.0      Linguistic            36.0  1.0  1.0  1.0   \n",
      "..                        ...             ...             ...  ...  ...  ...   \n",
      "192                       NaN  Non-Linguistic            96.0  NaN  NaN  NaN   \n",
      "193                       NaN  Non-Linguistic            92.0  NaN  NaN  NaN   \n",
      "194                       NaN  Non-Linguistic            80.0  NaN  NaN  NaN   \n",
      "195                       NaN  Non-Linguistic            56.0  NaN  NaN  NaN   \n",
      "196                       NaN  Non-Linguistic            48.0  NaN  NaN  NaN   \n",
      "197                       NaN  Non-Linguistic           100.0  NaN  NaN  NaN   \n",
      "198                       NaN  Non-Linguistic            60.0  NaN  NaN  NaN   \n",
      "199                       NaN  Non-Linguistic            68.0  NaN  NaN  NaN   \n",
      "200                       NaN  Non-Linguistic            96.0  NaN  NaN  NaN   \n",
      "201                       NaN  Non-Linguistic            80.0  NaN  NaN  NaN   \n",
      "202                       NaN  Non-Linguistic            64.0  NaN  NaN  NaN   \n",
      "203                       NaN  Non-Linguistic            72.0  NaN  NaN  NaN   \n",
      "204                       NaN  Non-Linguistic           100.0  NaN  NaN  NaN   \n",
      "205                       NaN  Non-Linguistic            52.0  NaN  NaN  NaN   \n",
      "206                       NaN  Non-Linguistic            92.0  NaN  NaN  NaN   \n",
      "207                       NaN  Non-Linguistic            64.0  NaN  NaN  NaN   \n",
      "208                       NaN  Non-Linguistic            96.0  NaN  NaN  NaN   \n",
      "209                       NaN  Non-Linguistic            48.0  NaN  NaN  NaN   \n",
      "210                       NaN  Non-Linguistic            48.0  NaN  NaN  NaN   \n",
      "211                       NaN  Non-Linguistic            56.0  NaN  NaN  NaN   \n",
      "212                       NaN  Non-Linguistic            52.0  NaN  NaN  NaN   \n",
      "213                       NaN  Non-Linguistic            72.0  NaN  NaN  NaN   \n",
      "214                       NaN  Non-Linguistic            60.0  NaN  NaN  NaN   \n",
      "215                       NaN  Non-Linguistic            80.0  NaN  NaN  NaN   \n",
      "216                       NaN  Non-Linguistic            76.0  NaN  NaN  NaN   \n",
      "217                       NaN  Non-Linguistic           100.0  NaN  NaN  NaN   \n",
      "218                       NaN  Non-Linguistic            64.0  NaN  NaN  NaN   \n",
      "219                       NaN  Non-Linguistic            88.0  NaN  NaN  NaN   \n",
      "220                       NaN  Non-Linguistic            60.0  NaN  NaN  NaN   \n",
      "221                       NaN  Non-Linguistic            40.0  NaN  NaN  NaN   \n",
      "\n",
      "      Q4   Q5  Average English Likeness  \n",
      "0    1.0  1.0                       1.0  \n",
      "1    NaN  NaN                       NaN  \n",
      "2    1.0  1.0                       1.4  \n",
      "3    2.0  0.0                       1.0  \n",
      "4    4.0  2.0                       2.8  \n",
      "5    5.0  2.0                       2.2  \n",
      "6    1.0  0.0                       0.4  \n",
      "7    1.0  4.0                       2.2  \n",
      "8    1.0  1.0                       1.4  \n",
      "9    3.0  2.0                       2.4  \n",
      "10   1.0  0.0                       0.8  \n",
      "11   0.0  0.0                       0.4  \n",
      "12   0.0  0.0                       0.0  \n",
      "13   4.0  0.0                       2.0  \n",
      "14   1.0  0.0                       1.0  \n",
      "15   3.0  2.0                       2.4  \n",
      "16   1.0  0.0                       1.8  \n",
      "17   5.0  4.0                       2.8  \n",
      "18   4.0  4.0                       2.8  \n",
      "19   0.0  0.0                       0.2  \n",
      "20   1.0  2.0                       1.2  \n",
      "21   0.0  1.0                       0.6  \n",
      "22   0.0  0.0                       0.2  \n",
      "23   0.0  1.0                       0.2  \n",
      "24   5.0  2.0                       2.8  \n",
      "25   1.0  1.0                       1.2  \n",
      "26   0.0  1.0                       0.2  \n",
      "27   1.0  1.0                       1.2  \n",
      "28   5.0  0.0                       1.8  \n",
      "29   0.0  0.0                       0.6  \n",
      "..   ...  ...                       ...  \n",
      "192  NaN  NaN                       NaN  \n",
      "193  NaN  NaN                       NaN  \n",
      "194  NaN  NaN                       NaN  \n",
      "195  NaN  NaN                       NaN  \n",
      "196  NaN  NaN                       NaN  \n",
      "197  NaN  NaN                       NaN  \n",
      "198  NaN  NaN                       NaN  \n",
      "199  NaN  NaN                       NaN  \n",
      "200  NaN  NaN                       NaN  \n",
      "201  NaN  NaN                       NaN  \n",
      "202  NaN  NaN                       NaN  \n",
      "203  NaN  NaN                       NaN  \n",
      "204  NaN  NaN                       NaN  \n",
      "205  NaN  NaN                       NaN  \n",
      "206  NaN  NaN                       NaN  \n",
      "207  NaN  NaN                       NaN  \n",
      "208  NaN  NaN                       NaN  \n",
      "209  NaN  NaN                       NaN  \n",
      "210  NaN  NaN                       NaN  \n",
      "211  NaN  NaN                       NaN  \n",
      "212  NaN  NaN                       NaN  \n",
      "213  NaN  NaN                       NaN  \n",
      "214  NaN  NaN                       NaN  \n",
      "215  NaN  NaN                       NaN  \n",
      "216  NaN  NaN                       NaN  \n",
      "217  NaN  NaN                       NaN  \n",
      "218  NaN  NaN                       NaN  \n",
      "219  NaN  NaN                       NaN  \n",
      "220  NaN  NaN                       NaN  \n",
      "221  NaN  NaN                       NaN  \n",
      "\n",
      "[222 rows x 15 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.random import normal\n",
    "import scipy.stats  as stats\n",
    "import researchpy as rp\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "df = pd.read_excel('/Users/julieschneider/Julie_Personal/Projects/HEB/HEB_data.xlsx', sheet_name='Sheet1')\n",
    "df.rename(columns={'Linguistic SL':'PercentCorrect'}, inplace=True)\n",
    "df.rename(columns={'SL':'Task'}, inplace=True)\n",
    "\n",
    "print(\"Column headings:\")\n",
    "print(df.columns)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>Author Task</th>\n",
       "      <th>Overall English Likeness</th>\n",
       "      <th>PercentCorrect</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Average English Likeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.343222</td>\n",
       "      <td>0.033147</td>\n",
       "      <td>-0.069968</td>\n",
       "      <td>0.016077</td>\n",
       "      <td>-0.056165</td>\n",
       "      <td>-0.030820</td>\n",
       "      <td>-0.001192</td>\n",
       "      <td>-0.089823</td>\n",
       "      <td>0.096083</td>\n",
       "      <td>-0.026934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vocabulary</th>\n",
       "      <td>-0.343222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.475738</td>\n",
       "      <td>-0.030332</td>\n",
       "      <td>0.143316</td>\n",
       "      <td>0.046631</td>\n",
       "      <td>0.035066</td>\n",
       "      <td>-0.037707</td>\n",
       "      <td>0.017028</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.017351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Author Task</th>\n",
       "      <td>0.033147</td>\n",
       "      <td>0.475738</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.189956</td>\n",
       "      <td>-0.184328</td>\n",
       "      <td>-0.085914</td>\n",
       "      <td>-0.107040</td>\n",
       "      <td>0.054499</td>\n",
       "      <td>0.078795</td>\n",
       "      <td>-0.046515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall English Likeness</th>\n",
       "      <td>-0.069968</td>\n",
       "      <td>-0.030332</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263332</td>\n",
       "      <td>0.541827</td>\n",
       "      <td>0.359286</td>\n",
       "      <td>0.412738</td>\n",
       "      <td>0.294408</td>\n",
       "      <td>0.391468</td>\n",
       "      <td>0.542512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentCorrect</th>\n",
       "      <td>0.016077</td>\n",
       "      <td>0.143316</td>\n",
       "      <td>0.189956</td>\n",
       "      <td>0.263332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214294</td>\n",
       "      <td>0.167952</td>\n",
       "      <td>0.069124</td>\n",
       "      <td>0.160666</td>\n",
       "      <td>0.150686</td>\n",
       "      <td>0.212458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>-0.056165</td>\n",
       "      <td>0.046631</td>\n",
       "      <td>-0.184328</td>\n",
       "      <td>0.541827</td>\n",
       "      <td>0.214294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408571</td>\n",
       "      <td>0.306582</td>\n",
       "      <td>0.310675</td>\n",
       "      <td>0.245021</td>\n",
       "      <td>0.597727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>-0.030820</td>\n",
       "      <td>0.035066</td>\n",
       "      <td>-0.085914</td>\n",
       "      <td>0.359286</td>\n",
       "      <td>0.167952</td>\n",
       "      <td>0.408571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409943</td>\n",
       "      <td>0.427996</td>\n",
       "      <td>0.687373</td>\n",
       "      <td>0.799879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3</th>\n",
       "      <td>-0.001192</td>\n",
       "      <td>-0.037707</td>\n",
       "      <td>-0.107040</td>\n",
       "      <td>0.412738</td>\n",
       "      <td>0.069124</td>\n",
       "      <td>0.306582</td>\n",
       "      <td>0.409943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397133</td>\n",
       "      <td>0.302585</td>\n",
       "      <td>0.661846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4</th>\n",
       "      <td>-0.089823</td>\n",
       "      <td>0.017028</td>\n",
       "      <td>0.054499</td>\n",
       "      <td>0.294408</td>\n",
       "      <td>0.160666</td>\n",
       "      <td>0.310675</td>\n",
       "      <td>0.427996</td>\n",
       "      <td>0.397133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.369036</td>\n",
       "      <td>0.762997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5</th>\n",
       "      <td>0.096083</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.078795</td>\n",
       "      <td>0.391468</td>\n",
       "      <td>0.150686</td>\n",
       "      <td>0.245021</td>\n",
       "      <td>0.687373</td>\n",
       "      <td>0.302585</td>\n",
       "      <td>0.369036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average English Likeness</th>\n",
       "      <td>-0.026934</td>\n",
       "      <td>0.017351</td>\n",
       "      <td>-0.046515</td>\n",
       "      <td>0.542512</td>\n",
       "      <td>0.212458</td>\n",
       "      <td>0.597727</td>\n",
       "      <td>0.799879</td>\n",
       "      <td>0.661846</td>\n",
       "      <td>0.762997</td>\n",
       "      <td>0.728857</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Age  Vocabulary  Author Task  \\\n",
       "Age                       1.000000   -0.343222     0.033147   \n",
       "Vocabulary               -0.343222    1.000000     0.475738   \n",
       "Author Task               0.033147    0.475738     1.000000   \n",
       "Overall English Likeness -0.069968   -0.030332     0.149600   \n",
       "PercentCorrect            0.016077    0.143316     0.189956   \n",
       "Q1                       -0.056165    0.046631    -0.184328   \n",
       "Q2                       -0.030820    0.035066    -0.085914   \n",
       "Q3                       -0.001192   -0.037707    -0.107040   \n",
       "Q4                       -0.089823    0.017028     0.054499   \n",
       "Q5                        0.096083    0.001293     0.078795   \n",
       "Average English Likeness -0.026934    0.017351    -0.046515   \n",
       "\n",
       "                          Overall English Likeness  PercentCorrect        Q1  \\\n",
       "Age                                      -0.069968        0.016077 -0.056165   \n",
       "Vocabulary                               -0.030332        0.143316  0.046631   \n",
       "Author Task                               0.149600        0.189956 -0.184328   \n",
       "Overall English Likeness                  1.000000        0.263332  0.541827   \n",
       "PercentCorrect                            0.263332        1.000000  0.214294   \n",
       "Q1                                        0.541827        0.214294  1.000000   \n",
       "Q2                                        0.359286        0.167952  0.408571   \n",
       "Q3                                        0.412738        0.069124  0.306582   \n",
       "Q4                                        0.294408        0.160666  0.310675   \n",
       "Q5                                        0.391468        0.150686  0.245021   \n",
       "Average English Likeness                  0.542512        0.212458  0.597727   \n",
       "\n",
       "                                Q2        Q3        Q4        Q5  \\\n",
       "Age                      -0.030820 -0.001192 -0.089823  0.096083   \n",
       "Vocabulary                0.035066 -0.037707  0.017028  0.001293   \n",
       "Author Task              -0.085914 -0.107040  0.054499  0.078795   \n",
       "Overall English Likeness  0.359286  0.412738  0.294408  0.391468   \n",
       "PercentCorrect            0.167952  0.069124  0.160666  0.150686   \n",
       "Q1                        0.408571  0.306582  0.310675  0.245021   \n",
       "Q2                        1.000000  0.409943  0.427996  0.687373   \n",
       "Q3                        0.409943  1.000000  0.397133  0.302585   \n",
       "Q4                        0.427996  0.397133  1.000000  0.369036   \n",
       "Q5                        0.687373  0.302585  0.369036  1.000000   \n",
       "Average English Likeness  0.799879  0.661846  0.762997  0.728857   \n",
       "\n",
       "                          Average English Likeness  \n",
       "Age                                      -0.026934  \n",
       "Vocabulary                                0.017351  \n",
       "Author Task                              -0.046515  \n",
       "Overall English Likeness                  0.542512  \n",
       "PercentCorrect                            0.212458  \n",
       "Q1                                        0.597727  \n",
       "Q2                                        0.799879  \n",
       "Q3                                        0.661846  \n",
       "Q4                                        0.762997  \n",
       "Q5                                        0.728857  \n",
       "Average English Likeness                  1.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>Author Task</th>\n",
       "      <th>Overall English Likeness</th>\n",
       "      <th>PercentCorrect</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Average English Likeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.343222</td>\n",
       "      <td>0.033147</td>\n",
       "      <td>-0.069968</td>\n",
       "      <td>0.047643</td>\n",
       "      <td>-0.056165</td>\n",
       "      <td>-0.030820</td>\n",
       "      <td>-0.001192</td>\n",
       "      <td>-0.089823</td>\n",
       "      <td>0.096083</td>\n",
       "      <td>-0.026934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vocabulary</th>\n",
       "      <td>-0.343222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.475738</td>\n",
       "      <td>-0.030332</td>\n",
       "      <td>0.350251</td>\n",
       "      <td>0.046631</td>\n",
       "      <td>0.035066</td>\n",
       "      <td>-0.037707</td>\n",
       "      <td>0.017028</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.017351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Author Task</th>\n",
       "      <td>0.033147</td>\n",
       "      <td>0.475738</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>0.341245</td>\n",
       "      <td>-0.184328</td>\n",
       "      <td>-0.085914</td>\n",
       "      <td>-0.107040</td>\n",
       "      <td>0.054499</td>\n",
       "      <td>0.078795</td>\n",
       "      <td>-0.046515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall English Likeness</th>\n",
       "      <td>-0.069968</td>\n",
       "      <td>-0.030332</td>\n",
       "      <td>0.149600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.263332</td>\n",
       "      <td>0.541827</td>\n",
       "      <td>0.359286</td>\n",
       "      <td>0.412738</td>\n",
       "      <td>0.294408</td>\n",
       "      <td>0.391468</td>\n",
       "      <td>0.542512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentCorrect</th>\n",
       "      <td>0.047643</td>\n",
       "      <td>0.350251</td>\n",
       "      <td>0.341245</td>\n",
       "      <td>0.263332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.214294</td>\n",
       "      <td>0.167952</td>\n",
       "      <td>0.069124</td>\n",
       "      <td>0.160666</td>\n",
       "      <td>0.150686</td>\n",
       "      <td>0.212458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>-0.056165</td>\n",
       "      <td>0.046631</td>\n",
       "      <td>-0.184328</td>\n",
       "      <td>0.541827</td>\n",
       "      <td>0.214294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408571</td>\n",
       "      <td>0.306582</td>\n",
       "      <td>0.310675</td>\n",
       "      <td>0.245021</td>\n",
       "      <td>0.597727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>-0.030820</td>\n",
       "      <td>0.035066</td>\n",
       "      <td>-0.085914</td>\n",
       "      <td>0.359286</td>\n",
       "      <td>0.167952</td>\n",
       "      <td>0.408571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409943</td>\n",
       "      <td>0.427996</td>\n",
       "      <td>0.687373</td>\n",
       "      <td>0.799879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3</th>\n",
       "      <td>-0.001192</td>\n",
       "      <td>-0.037707</td>\n",
       "      <td>-0.107040</td>\n",
       "      <td>0.412738</td>\n",
       "      <td>0.069124</td>\n",
       "      <td>0.306582</td>\n",
       "      <td>0.409943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.397133</td>\n",
       "      <td>0.302585</td>\n",
       "      <td>0.661846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4</th>\n",
       "      <td>-0.089823</td>\n",
       "      <td>0.017028</td>\n",
       "      <td>0.054499</td>\n",
       "      <td>0.294408</td>\n",
       "      <td>0.160666</td>\n",
       "      <td>0.310675</td>\n",
       "      <td>0.427996</td>\n",
       "      <td>0.397133</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.369036</td>\n",
       "      <td>0.762997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5</th>\n",
       "      <td>0.096083</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.078795</td>\n",
       "      <td>0.391468</td>\n",
       "      <td>0.150686</td>\n",
       "      <td>0.245021</td>\n",
       "      <td>0.687373</td>\n",
       "      <td>0.302585</td>\n",
       "      <td>0.369036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average English Likeness</th>\n",
       "      <td>-0.026934</td>\n",
       "      <td>0.017351</td>\n",
       "      <td>-0.046515</td>\n",
       "      <td>0.542512</td>\n",
       "      <td>0.212458</td>\n",
       "      <td>0.597727</td>\n",
       "      <td>0.799879</td>\n",
       "      <td>0.661846</td>\n",
       "      <td>0.762997</td>\n",
       "      <td>0.728857</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Age  Vocabulary  Author Task  \\\n",
       "Age                       1.000000   -0.343222     0.033147   \n",
       "Vocabulary               -0.343222    1.000000     0.475738   \n",
       "Author Task               0.033147    0.475738     1.000000   \n",
       "Overall English Likeness -0.069968   -0.030332     0.149600   \n",
       "PercentCorrect            0.047643    0.350251     0.341245   \n",
       "Q1                       -0.056165    0.046631    -0.184328   \n",
       "Q2                       -0.030820    0.035066    -0.085914   \n",
       "Q3                       -0.001192   -0.037707    -0.107040   \n",
       "Q4                       -0.089823    0.017028     0.054499   \n",
       "Q5                        0.096083    0.001293     0.078795   \n",
       "Average English Likeness -0.026934    0.017351    -0.046515   \n",
       "\n",
       "                          Overall English Likeness  PercentCorrect        Q1  \\\n",
       "Age                                      -0.069968        0.047643 -0.056165   \n",
       "Vocabulary                               -0.030332        0.350251  0.046631   \n",
       "Author Task                               0.149600        0.341245 -0.184328   \n",
       "Overall English Likeness                  1.000000        0.263332  0.541827   \n",
       "PercentCorrect                            0.263332        1.000000  0.214294   \n",
       "Q1                                        0.541827        0.214294  1.000000   \n",
       "Q2                                        0.359286        0.167952  0.408571   \n",
       "Q3                                        0.412738        0.069124  0.306582   \n",
       "Q4                                        0.294408        0.160666  0.310675   \n",
       "Q5                                        0.391468        0.150686  0.245021   \n",
       "Average English Likeness                  0.542512        0.212458  0.597727   \n",
       "\n",
       "                                Q2        Q3        Q4        Q5  \\\n",
       "Age                      -0.030820 -0.001192 -0.089823  0.096083   \n",
       "Vocabulary                0.035066 -0.037707  0.017028  0.001293   \n",
       "Author Task              -0.085914 -0.107040  0.054499  0.078795   \n",
       "Overall English Likeness  0.359286  0.412738  0.294408  0.391468   \n",
       "PercentCorrect            0.167952  0.069124  0.160666  0.150686   \n",
       "Q1                        0.408571  0.306582  0.310675  0.245021   \n",
       "Q2                        1.000000  0.409943  0.427996  0.687373   \n",
       "Q3                        0.409943  1.000000  0.397133  0.302585   \n",
       "Q4                        0.427996  0.397133  1.000000  0.369036   \n",
       "Q5                        0.687373  0.302585  0.369036  1.000000   \n",
       "Average English Likeness  0.799879  0.661846  0.762997  0.728857   \n",
       "\n",
       "                          Average English Likeness  \n",
       "Age                                      -0.026934  \n",
       "Vocabulary                                0.017351  \n",
       "Author Task                              -0.046515  \n",
       "Overall English Likeness                  0.542512  \n",
       "PercentCorrect                            0.212458  \n",
       "Q1                                        0.597727  \n",
       "Q2                                        0.799879  \n",
       "Q3                                        0.661846  \n",
       "Q4                                        0.762997  \n",
       "Q5                                        0.728857  \n",
       "Average English Likeness                  1.000000  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Just analyzing a single variable (in this case only linguistic SL Task)\n",
    "df_corrdata = df[(df.Task) == 'Linguistic']\n",
    "df_corrdata\n",
    "df_corrdata.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1774025508384296, 0.07897275610603462)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Correlation with R and p-value\n",
    "df_clean=df.dropna()\n",
    "stats.pearsonr(df_clean['PercentCorrect'],df_clean['Overall English Likeness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>Author Task</th>\n",
       "      <th>Overall English Likeness</th>\n",
       "      <th>PercentCorrect</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Average English Likeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.5187</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.7528</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.7619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vocabulary</th>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.6633</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>0.8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Author Task</th>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6541</td>\n",
       "      <td>0.1116</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.5731</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.6643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall English Likeness</th>\n",
       "      <td>0.5187</td>\n",
       "      <td>0.6633</td>\n",
       "      <td>0.6541</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1196</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentCorrect</th>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.1116</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.7883</td>\n",
       "      <td>0.3803</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>0.7528</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.5731</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3</th>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.7883</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4</th>\n",
       "      <td>0.4613</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>0.1196</td>\n",
       "      <td>0.3803</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5</th>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average English Likeness</th>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.6643</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Age Vocabulary Author Task  \\\n",
       "Age                       0.0000     0.0041      0.8933   \n",
       "Vocabulary                0.0041     0.0000      0.0021   \n",
       "Author Task               0.8933     0.0021      0.0000   \n",
       "Overall English Likeness  0.5187     0.6633      0.6541   \n",
       "PercentCorrect            0.0280     0.0744      0.1116   \n",
       "Q1                        0.6610     0.9443      0.2191   \n",
       "Q2                        0.7528     0.7562      0.5731   \n",
       "Q3                        0.9057     0.9385      0.2279   \n",
       "Q4                        0.4613     0.9566      0.8164   \n",
       "Q5                        0.5371     0.9492      0.5144   \n",
       "Average English Likeness  0.7619     0.8800      0.6643   \n",
       "\n",
       "                         Overall English Likeness PercentCorrect      Q1  \\\n",
       "Age                                        0.5187         0.0280  0.6610   \n",
       "Vocabulary                                 0.6633         0.0744  0.9443   \n",
       "Author Task                                0.6541         0.1116  0.2191   \n",
       "Overall English Likeness                   0.0000         0.1070  0.0000   \n",
       "PercentCorrect                             0.1070         0.0000  0.1346   \n",
       "Q1                                         0.0000         0.1346  0.0000   \n",
       "Q2                                         0.0129         0.1870  0.0033   \n",
       "Q3                                         0.0233         0.7883  0.0123   \n",
       "Q4                                         0.1196         0.3803  0.0276   \n",
       "Q5                                         0.0068         0.1870  0.0582   \n",
       "Average English Likeness                   0.0001         0.1392  0.0000   \n",
       "\n",
       "                              Q2      Q3      Q4      Q5  \\\n",
       "Age                       0.7528  0.9057  0.4613  0.5371   \n",
       "Vocabulary                0.7562  0.9385  0.9566  0.9492   \n",
       "Author Task               0.5731  0.2279  0.8164  0.5144   \n",
       "Overall English Likeness  0.0129  0.0233  0.1196  0.0068   \n",
       "PercentCorrect            0.1870  0.7883  0.3803  0.1870   \n",
       "Q1                        0.0033  0.0123  0.0276  0.0582   \n",
       "Q2                        0.0000  0.0056  0.0040  0.0000   \n",
       "Q3                        0.0056  0.0000  0.0217  0.0386   \n",
       "Q4                        0.0040  0.0217  0.0000  0.0090   \n",
       "Q5                        0.0000  0.0386  0.0090  0.0000   \n",
       "Average English Likeness  0.0000  0.0000  0.0000  0.0000   \n",
       "\n",
       "                         Average English Likeness  \n",
       "Age                                        0.7619  \n",
       "Vocabulary                                 0.8800  \n",
       "Author Task                                0.6643  \n",
       "Overall English Likeness                   0.0001  \n",
       "PercentCorrect                             0.1392  \n",
       "Q1                                         0.0000  \n",
       "Q2                                         0.0000  \n",
       "Q3                                         0.0000  \n",
       "Q4                                         0.0000  \n",
       "Q5                                         0.0000  \n",
       "Average English Likeness                   0.0000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimal method for running correlation (full matrix)\n",
    "df_corrdata = df[(df.Task) == 'Linguistic']\n",
    "corr_type, corr_matrix, corr_ps = rp.corr_case(df_corrdata)\n",
    "\n",
    "#corr_matrix\n",
    "corr_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>PercentCorrect</td>  <th>  R-squared:         </th> <td>   0.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.561</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   64.82</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 07 Dec 2018</td> <th>  Prob (F-statistic):</th> <td>1.60e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>12:48:04</td>     <th>  Log-Likelihood:    </th> <td> -252.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   506.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    49</td>      <th>  BIC:               </th> <td>   508.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Overall English Likeness</th> <td>   30.0583</td> <td>    3.733</td> <td>    8.051</td> <td> 0.000</td> <td>   22.556</td> <td>   37.561</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.969</td> <th>  Durbin-Watson:     </th> <td>   1.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.616</td> <th>  Jarque-Bera (JB):  </th> <td>   0.921</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.311</td> <th>  Prob(JB):          </th> <td>   0.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.764</td> <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:         PercentCorrect   R-squared:                       0.569\n",
       "Model:                            OLS   Adj. R-squared:                  0.561\n",
       "Method:                 Least Squares   F-statistic:                     64.82\n",
       "Date:                Fri, 07 Dec 2018   Prob (F-statistic):           1.60e-10\n",
       "Time:                        12:48:04   Log-Likelihood:                -252.18\n",
       "No. Observations:                  50   AIC:                             506.4\n",
       "Df Residuals:                      49   BIC:                             508.3\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "============================================================================================\n",
       "                               coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------\n",
       "Overall English Likeness    30.0583      3.733      8.051      0.000      22.556      37.561\n",
       "==============================================================================\n",
       "Omnibus:                        0.969   Durbin-Watson:                   1.144\n",
       "Prob(Omnibus):                  0.616   Jarque-Bera (JB):                0.921\n",
       "Skew:                          -0.311   Prob(JB):                        0.631\n",
       "Kurtosis:                       2.764   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regression with R and p-value\n",
    "df_clean=df.dropna()\n",
    "X = df_clean[\"Overall English Likeness\"]\n",
    "y = df_clean[\"PercentCorrect\"]\n",
    "\n",
    "# Note the difference in argument order\n",
    "model = sm.OLS(y, X).fit()\n",
    "predictions = model.predict(X) # make the predictions by the model\n",
    "\n",
    "# Print out the statistics\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object arrays are not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-572ffde8986f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mP_corr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mpartial_corr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-72-572ffde8986f>\u001b[0m in \u001b[0;36mpartial_corr\u001b[0;34m(C)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mbeta_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mbeta_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36mlstsq\u001b[0;34m(a, b, cond, overwrite_a, overwrite_b, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \"\"\"\n\u001b[0;32m-> 1154\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m     \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobjects_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'object arrays are not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mas_inexact\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minexact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: object arrays are not supported"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats, linalg\n",
    "\n",
    "def partial_corr(C):\n",
    "    \"\"\"\n",
    "    Returns the sample linear partial correlation coefficients between pairs of variables in C, controlling \n",
    "    for the remaining variables in C.\n",
    "    Parameters\n",
    "    ----------\n",
    "    C : array-like, shape (n, p)\n",
    "        Array with the different variables. Each column of C is taken as a variable\n",
    "    Returns\n",
    "    -------\n",
    "    P : array-like, shape (p, p)\n",
    "        P[i, j] contains the partial correlation of C[:, i] and C[:, j] controlling\n",
    "        for the remaining variables in C.\n",
    "    \"\"\"\n",
    "    \n",
    "    C = np.asarray(C)\n",
    "    p = C.shape[1]\n",
    "    P_corr = np.zeros((p, p), dtype=np.float)\n",
    "    for i in range(p):\n",
    "        P_corr[i, i] = 1\n",
    "        for j in range(i+1, p):\n",
    "            idx = np.ones(p, dtype=np.bool)\n",
    "            idx[i] = False\n",
    "            idx[j] = False\n",
    "            beta_i = linalg.lstsq(C[:, idx], C[:, j])[0]\n",
    "            beta_j = linalg.lstsq(C[:, idx], C[:, i])[0]\n",
    "\n",
    "            res_j = C[:, j] - C[:, idx].dot( beta_i)\n",
    "            res_i = C[:, i] - C[:, idx].dot(beta_j)\n",
    "            \n",
    "            corr = stats.pearsonr(res_i, res_j)[0]\n",
    "            P_corr[i, j] = corr\n",
    "            P_corr[j, i] = corr\n",
    "        \n",
    "    return P_corr\n",
    "\n",
    "partial_corr(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-2.3402777931329646, pvalue=0.023385644198802524)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#paired samples t-test\n",
    "df_clean=df.dropna()\n",
    "X = df_clean[\"Overall English Likeness\"]\n",
    "y = df_clean[\"Average English Likeness\"]\n",
    "stats.ttest_rel(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>Author Task</th>\n",
       "      <th>Overall English Likeness</th>\n",
       "      <th>PercentCorrect</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Average English Likeness</th>\n",
       "      <th>Likeness Inconsistency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.5187</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.7528</td>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.6808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vocabulary</th>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.6633</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.5408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Author Task</th>\n",
       "      <td>0.8933</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6541</td>\n",
       "      <td>0.1116</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.5731</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.6643</td>\n",
       "      <td>0.3723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overall English Likeness</th>\n",
       "      <td>0.5187</td>\n",
       "      <td>0.6633</td>\n",
       "      <td>0.6541</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1196</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentCorrect</th>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.1116</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.7883</td>\n",
       "      <td>0.3803</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.7292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q1</th>\n",
       "      <td>0.6610</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1346</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q2</th>\n",
       "      <td>0.7528</td>\n",
       "      <td>0.7562</td>\n",
       "      <td>0.5731</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q3</th>\n",
       "      <td>0.9057</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>0.2279</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.7883</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q4</th>\n",
       "      <td>0.4613</td>\n",
       "      <td>0.9566</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>0.1196</td>\n",
       "      <td>0.3803</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5</th>\n",
       "      <td>0.5371</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average English Likeness</th>\n",
       "      <td>0.7619</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>0.6643</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Likeness Inconsistency</th>\n",
       "      <td>0.6808</td>\n",
       "      <td>0.5408</td>\n",
       "      <td>0.3723</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7292</td>\n",
       "      <td>0.4414</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Age Vocabulary Author Task  \\\n",
       "Age                       0.0000     0.0041      0.8933   \n",
       "Vocabulary                0.0041     0.0000      0.0021   \n",
       "Author Task               0.8933     0.0021      0.0000   \n",
       "Overall English Likeness  0.5187     0.6633      0.6541   \n",
       "PercentCorrect            0.0280     0.0744      0.1116   \n",
       "Q1                        0.6610     0.9443      0.2191   \n",
       "Q2                        0.7528     0.7562      0.5731   \n",
       "Q3                        0.9057     0.9385      0.2279   \n",
       "Q4                        0.4613     0.9566      0.8164   \n",
       "Q5                        0.5371     0.9492      0.5144   \n",
       "Average English Likeness  0.7619     0.8800      0.6643   \n",
       "Likeness Inconsistency    0.6808     0.5408      0.3723   \n",
       "\n",
       "                         Overall English Likeness PercentCorrect      Q1  \\\n",
       "Age                                        0.5187         0.0280  0.6610   \n",
       "Vocabulary                                 0.6633         0.0744  0.9443   \n",
       "Author Task                                0.6541         0.1116  0.2191   \n",
       "Overall English Likeness                   0.0000         0.1070  0.0000   \n",
       "PercentCorrect                             0.1070         0.0000  0.1346   \n",
       "Q1                                         0.0000         0.1346  0.0000   \n",
       "Q2                                         0.0129         0.1870  0.0033   \n",
       "Q3                                         0.0233         0.7883  0.0123   \n",
       "Q4                                         0.1196         0.3803  0.0276   \n",
       "Q5                                         0.0068         0.1870  0.0582   \n",
       "Average English Likeness                   0.0001         0.1392  0.0000   \n",
       "Likeness Inconsistency                     0.0000         0.7292  0.4414   \n",
       "\n",
       "                              Q2      Q3      Q4      Q5  \\\n",
       "Age                       0.7528  0.9057  0.4613  0.5371   \n",
       "Vocabulary                0.7562  0.9385  0.9566  0.9492   \n",
       "Author Task               0.5731  0.2279  0.8164  0.5144   \n",
       "Overall English Likeness  0.0129  0.0233  0.1196  0.0068   \n",
       "PercentCorrect            0.1870  0.7883  0.3803  0.1870   \n",
       "Q1                        0.0033  0.0123  0.0276  0.0582   \n",
       "Q2                        0.0000  0.0056  0.0040  0.0000   \n",
       "Q3                        0.0056  0.0000  0.0217  0.0386   \n",
       "Q4                        0.0040  0.0217  0.0000  0.0090   \n",
       "Q5                        0.0000  0.0386  0.0090  0.0000   \n",
       "Average English Likeness  0.0000  0.0000  0.0000  0.0000   \n",
       "Likeness Inconsistency    0.0087  0.0857  0.0010  0.0419   \n",
       "\n",
       "                         Average English Likeness Likeness Inconsistency  \n",
       "Age                                        0.7619                 0.6808  \n",
       "Vocabulary                                 0.8800                 0.5408  \n",
       "Author Task                                0.6643                 0.3723  \n",
       "Overall English Likeness                   0.0001                 0.0000  \n",
       "PercentCorrect                             0.1392                 0.7292  \n",
       "Q1                                         0.0000                 0.4414  \n",
       "Q2                                         0.0000                 0.0087  \n",
       "Q3                                         0.0000                 0.0857  \n",
       "Q4                                         0.0000                 0.0010  \n",
       "Q5                                         0.0000                 0.0419  \n",
       "Average English Likeness                   0.0000                 0.0063  \n",
       "Likeness Inconsistency                     0.0063                 0.0000  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Diff=df[\"Overall English Likeness\"] - df[\"Average English Likeness\"]\n",
    "df['Likeness Inconsistency'] = Diff\n",
    "#Optimal method for running correlation (full matrix)\n",
    "df_corrdata = df[(df.Task) == 'Linguistic']\n",
    "corr_type, corr_matrix, corr_ps = rp.corr_case(df_corrdata)\n",
    "\n",
    "#corr_matrix\n",
    "corr_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lmplot(x=\"Likeness Inconsistency\", y=\"PercentCorrect\", data=df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Language</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Vocabulary</th>\n",
       "      <th>Author Task</th>\n",
       "      <th>Overall English Likeness</th>\n",
       "      <th>Task</th>\n",
       "      <th>PercentCorrect</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Average English Likeness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a_001</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>102.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a_002</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>19</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a_003</td>\n",
       "      <td>English</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a_004</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>19</td>\n",
       "      <td>115.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a_005</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>102.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>76.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a_006</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>102.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a_007</td>\n",
       "      <td>English</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>133.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a_008</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>96.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a_009</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>114.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a_010</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a_011</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a_012</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>96.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a_013</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>18</td>\n",
       "      <td>110.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a_014</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>119.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a_015</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>113.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a_016</td>\n",
       "      <td>English</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>127.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a_017</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>120.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a_019</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>30</td>\n",
       "      <td>114.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>a_020</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>126.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>a_021</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>113.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>a_022</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>131.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>a_023</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>18</td>\n",
       "      <td>116.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>a_024</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>19</td>\n",
       "      <td>115.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>a_025</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>a_026</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a_027</td>\n",
       "      <td>English</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>88.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>a_028</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>37</td>\n",
       "      <td>79.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>a_029</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>114.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>a_030</td>\n",
       "      <td>English</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>91.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>a_031</td>\n",
       "      <td>English</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>107.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linguistic</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>129</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>130</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>131</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>133</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>134</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>135</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>136</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>137</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>138</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>139</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>141</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>142</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>145</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Male</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>146</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>148</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>149</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>150</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>152</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>153</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>154</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>155</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>52.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>156</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>157</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>159</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>160</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>161</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Male</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>162</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>164</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>165</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>166</td>\n",
       "      <td>Hebrew</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-Linguistic</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject Language  Gender  Age  Vocabulary  Author Task  \\\n",
       "0     a_001  English  Female   21       102.0          NaN   \n",
       "1     a_002  English  Female   19        98.0         -9.0   \n",
       "2     a_003  English    Male   19        92.0         -4.0   \n",
       "3     a_004  English  Female   19       115.0         12.0   \n",
       "4     a_005  English  Female   21       102.0         19.0   \n",
       "5     a_006  English  Female   21       102.0         14.0   \n",
       "6     a_007  English    Male   19       133.0          4.0   \n",
       "7     a_008  English  Female   21        96.0          8.0   \n",
       "8     a_009  English  Female   20       114.0          3.0   \n",
       "9     a_010  English  Female   20       103.0          1.0   \n",
       "10    a_011  English  Female   20        97.0          2.0   \n",
       "11    a_012  English  Female   21        96.0         10.0   \n",
       "12    a_013  English  Female   18       110.0          9.0   \n",
       "13    a_014  English  Female   21       119.0         18.0   \n",
       "14    a_015  English  Female   22       113.0         11.0   \n",
       "15    a_016  English    Male   19       127.0          6.0   \n",
       "16    a_017  English  Female   20       120.0          5.0   \n",
       "17    a_019  English  Female   30       114.0         23.0   \n",
       "18    a_020  English  Female   20       126.0         20.0   \n",
       "19    a_021  English  Female   21       113.0         12.0   \n",
       "20    a_022  English  Female   21       131.0         32.0   \n",
       "21    a_023  English  Female   18       116.0         23.0   \n",
       "22    a_024  English  Female   19       115.0         17.0   \n",
       "23    a_025  English  Female   19         NaN         18.0   \n",
       "24    a_026  English  Female   21         NaN         20.0   \n",
       "25    a_027  English    Male   26        88.0         -7.0   \n",
       "26    a_028  English  Female   37        79.0          6.0   \n",
       "27    a_029  English  Female   20       114.0         14.0   \n",
       "28    a_030  English  Female   20        91.0          4.0   \n",
       "29    a_031  English    Male   35       107.0          2.0   \n",
       "..      ...      ...     ...  ...         ...          ...   \n",
       "192     129   Hebrew  Female   24         NaN          NaN   \n",
       "193     130   Hebrew  Female   23         NaN          NaN   \n",
       "194     131   Hebrew  Female   23         NaN          NaN   \n",
       "195     133   Hebrew  Female   21         NaN          NaN   \n",
       "196     134   Hebrew    Male   25         NaN          NaN   \n",
       "197     135   Hebrew  Female   23         NaN          NaN   \n",
       "198     136   Hebrew  Female   23         NaN          NaN   \n",
       "199     137   Hebrew  Female   23         NaN          NaN   \n",
       "200     138   Hebrew    Male   24         NaN          NaN   \n",
       "201     139   Hebrew  Female   23         NaN          NaN   \n",
       "202     141   Hebrew    Male   24         NaN          NaN   \n",
       "203     142   Hebrew  Female   21         NaN          NaN   \n",
       "204     145   Hebrew    Male   23         NaN          NaN   \n",
       "205     146   Hebrew  Female   22         NaN          NaN   \n",
       "206     148   Hebrew  Female   24         NaN          NaN   \n",
       "207     149   Hebrew  Female   25         NaN          NaN   \n",
       "208     150   Hebrew  Female   23         NaN          NaN   \n",
       "209     152   Hebrew  Female   20         NaN          NaN   \n",
       "210     153   Hebrew  Female   22         NaN          NaN   \n",
       "211     154   Hebrew    Male   25         NaN          NaN   \n",
       "212     155   Hebrew  Female   22         NaN          NaN   \n",
       "213     156   Hebrew  Female   19         NaN          NaN   \n",
       "214     157   Hebrew  Female   25         NaN          NaN   \n",
       "215     159   Hebrew    Male   24         NaN          NaN   \n",
       "216     160   Hebrew  Female   22         NaN          NaN   \n",
       "217     161   Hebrew    Male   22         NaN          NaN   \n",
       "218     162   Hebrew  Female   25         NaN          NaN   \n",
       "219     164   Hebrew  Female   21         NaN          NaN   \n",
       "220     165   Hebrew    Male   24         NaN          NaN   \n",
       "221     166   Hebrew  Female   25         NaN          NaN   \n",
       "\n",
       "     Overall English Likeness            Task  PercentCorrect   Q1   Q2   Q3  \\\n",
       "0                         1.0      Linguistic            56.0  1.0  1.0  1.0   \n",
       "1                         NaN      Linguistic             NaN  NaN  NaN  NaN   \n",
       "2                         1.0      Linguistic            44.0  2.0  1.0  2.0   \n",
       "3                         0.0      Linguistic            76.0  1.0  1.0  1.0   \n",
       "4                         4.0      Linguistic            76.0  4.0  2.0  2.0   \n",
       "5                         2.0      Linguistic            60.0  1.0  1.0  2.0   \n",
       "6                         1.0      Linguistic            64.0  1.0  0.0  0.0   \n",
       "7                         3.0      Linguistic            76.0  2.0  2.0  2.0   \n",
       "8                         0.0      Linguistic            60.0  2.0  2.0  1.0   \n",
       "9                         2.0      Linguistic            48.0  4.0  2.0  1.0   \n",
       "10                        1.0      Linguistic            36.0  1.0  2.0  0.0   \n",
       "11                        1.0      Linguistic            56.0  1.0  1.0  0.0   \n",
       "12                        0.0      Linguistic            44.0  0.0  0.0  0.0   \n",
       "13                        1.0      Linguistic            52.0  1.0  1.0  4.0   \n",
       "14                        0.0      Linguistic            56.0  1.0  1.0  2.0   \n",
       "15                        2.0      Linguistic            68.0  2.0  3.0  2.0   \n",
       "16                        1.0      Linguistic            48.0  2.0  2.0  4.0   \n",
       "17                        1.0      Linguistic            52.0  2.0  2.0  1.0   \n",
       "18                        3.0      Linguistic            60.0  1.0  3.0  2.0   \n",
       "19                        1.0      Linguistic            44.0  1.0  0.0  0.0   \n",
       "20                        1.0      Linguistic            68.0  2.0  1.0  0.0   \n",
       "21                        1.0      Linguistic            56.0  0.0  1.0  1.0   \n",
       "22                        1.0      Linguistic            64.0  1.0  0.0  0.0   \n",
       "23                        1.0      Linguistic            64.0  0.0  0.0  0.0   \n",
       "24                        4.0      Linguistic            80.0  1.0  2.0  4.0   \n",
       "25                        0.0      Linguistic            28.0  1.0  1.0  2.0   \n",
       "26                        0.0      Linguistic            40.0  0.0  0.0  0.0   \n",
       "27                        2.0      Linguistic            60.0  2.0  1.0  1.0   \n",
       "28                        2.0      Linguistic            48.0  2.0  0.0  2.0   \n",
       "29                        1.0      Linguistic            36.0  1.0  1.0  1.0   \n",
       "..                        ...             ...             ...  ...  ...  ...   \n",
       "192                       NaN  Non-Linguistic            96.0  NaN  NaN  NaN   \n",
       "193                       NaN  Non-Linguistic            92.0  NaN  NaN  NaN   \n",
       "194                       NaN  Non-Linguistic            80.0  NaN  NaN  NaN   \n",
       "195                       NaN  Non-Linguistic            56.0  NaN  NaN  NaN   \n",
       "196                       NaN  Non-Linguistic            48.0  NaN  NaN  NaN   \n",
       "197                       NaN  Non-Linguistic           100.0  NaN  NaN  NaN   \n",
       "198                       NaN  Non-Linguistic            60.0  NaN  NaN  NaN   \n",
       "199                       NaN  Non-Linguistic            68.0  NaN  NaN  NaN   \n",
       "200                       NaN  Non-Linguistic            96.0  NaN  NaN  NaN   \n",
       "201                       NaN  Non-Linguistic            80.0  NaN  NaN  NaN   \n",
       "202                       NaN  Non-Linguistic            64.0  NaN  NaN  NaN   \n",
       "203                       NaN  Non-Linguistic            72.0  NaN  NaN  NaN   \n",
       "204                       NaN  Non-Linguistic           100.0  NaN  NaN  NaN   \n",
       "205                       NaN  Non-Linguistic            52.0  NaN  NaN  NaN   \n",
       "206                       NaN  Non-Linguistic            92.0  NaN  NaN  NaN   \n",
       "207                       NaN  Non-Linguistic            64.0  NaN  NaN  NaN   \n",
       "208                       NaN  Non-Linguistic            96.0  NaN  NaN  NaN   \n",
       "209                       NaN  Non-Linguistic            48.0  NaN  NaN  NaN   \n",
       "210                       NaN  Non-Linguistic            48.0  NaN  NaN  NaN   \n",
       "211                       NaN  Non-Linguistic            56.0  NaN  NaN  NaN   \n",
       "212                       NaN  Non-Linguistic            52.0  NaN  NaN  NaN   \n",
       "213                       NaN  Non-Linguistic            72.0  NaN  NaN  NaN   \n",
       "214                       NaN  Non-Linguistic            60.0  NaN  NaN  NaN   \n",
       "215                       NaN  Non-Linguistic            80.0  NaN  NaN  NaN   \n",
       "216                       NaN  Non-Linguistic            76.0  NaN  NaN  NaN   \n",
       "217                       NaN  Non-Linguistic           100.0  NaN  NaN  NaN   \n",
       "218                       NaN  Non-Linguistic            64.0  NaN  NaN  NaN   \n",
       "219                       NaN  Non-Linguistic            88.0  NaN  NaN  NaN   \n",
       "220                       NaN  Non-Linguistic            60.0  NaN  NaN  NaN   \n",
       "221                       NaN  Non-Linguistic            40.0  NaN  NaN  NaN   \n",
       "\n",
       "      Q4   Q5  Average English Likeness  \n",
       "0    1.0  1.0                       1.0  \n",
       "1    NaN  NaN                       NaN  \n",
       "2    1.0  1.0                       1.4  \n",
       "3    2.0  0.0                       1.0  \n",
       "4    4.0  2.0                       2.8  \n",
       "5    5.0  2.0                       2.2  \n",
       "6    1.0  0.0                       0.4  \n",
       "7    1.0  4.0                       2.2  \n",
       "8    1.0  1.0                       1.4  \n",
       "9    3.0  2.0                       2.4  \n",
       "10   1.0  0.0                       0.8  \n",
       "11   0.0  0.0                       0.4  \n",
       "12   0.0  0.0                       0.0  \n",
       "13   4.0  0.0                       2.0  \n",
       "14   1.0  0.0                       1.0  \n",
       "15   3.0  2.0                       2.4  \n",
       "16   1.0  0.0                       1.8  \n",
       "17   5.0  4.0                       2.8  \n",
       "18   4.0  4.0                       2.8  \n",
       "19   0.0  0.0                       0.2  \n",
       "20   1.0  2.0                       1.2  \n",
       "21   0.0  1.0                       0.6  \n",
       "22   0.0  0.0                       0.2  \n",
       "23   0.0  1.0                       0.2  \n",
       "24   5.0  2.0                       2.8  \n",
       "25   1.0  1.0                       1.2  \n",
       "26   0.0  1.0                       0.2  \n",
       "27   1.0  1.0                       1.2  \n",
       "28   5.0  0.0                       1.8  \n",
       "29   0.0  0.0                       0.6  \n",
       "..   ...  ...                       ...  \n",
       "192  NaN  NaN                       NaN  \n",
       "193  NaN  NaN                       NaN  \n",
       "194  NaN  NaN                       NaN  \n",
       "195  NaN  NaN                       NaN  \n",
       "196  NaN  NaN                       NaN  \n",
       "197  NaN  NaN                       NaN  \n",
       "198  NaN  NaN                       NaN  \n",
       "199  NaN  NaN                       NaN  \n",
       "200  NaN  NaN                       NaN  \n",
       "201  NaN  NaN                       NaN  \n",
       "202  NaN  NaN                       NaN  \n",
       "203  NaN  NaN                       NaN  \n",
       "204  NaN  NaN                       NaN  \n",
       "205  NaN  NaN                       NaN  \n",
       "206  NaN  NaN                       NaN  \n",
       "207  NaN  NaN                       NaN  \n",
       "208  NaN  NaN                       NaN  \n",
       "209  NaN  NaN                       NaN  \n",
       "210  NaN  NaN                       NaN  \n",
       "211  NaN  NaN                       NaN  \n",
       "212  NaN  NaN                       NaN  \n",
       "213  NaN  NaN                       NaN  \n",
       "214  NaN  NaN                       NaN  \n",
       "215  NaN  NaN                       NaN  \n",
       "216  NaN  NaN                       NaN  \n",
       "217  NaN  NaN                       NaN  \n",
       "218  NaN  NaN                       NaN  \n",
       "219  NaN  NaN                       NaN  \n",
       "220  NaN  NaN                       NaN  \n",
       "221  NaN  NaN                       NaN  \n",
       "\n",
       "[222 rows x 15 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "PatsyError",
     "evalue": "Error evaluating factor: NameError: name 'Language' is not defined\n    Language ~ Task * Gender\n    ^^^^^^^^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/patsy/compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/patsy/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, source_name, inner_namespace)\u001b[0m\n\u001b[1;32m    165\u001b[0m         return eval(code, {}, VarLookupDict([inner_namespace]\n\u001b[0;32m--> 166\u001b[0;31m                                             + self._namespaces))\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Language' is not defined",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mPatsyError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3203c73af6a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# formula = 'Language ~ Task'               # Simple regression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mformula\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Language ~ Task * Gender'\u001b[0m  \u001b[0;31m# ANCOVA formula\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PercentCorrect'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/statsmodels/base/model.py\u001b[0m in \u001b[0;36mfrom_formula\u001b[0;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         tmp = handle_formula_data(data, None, formula, depth=eval_env,\n\u001b[0;32m--> 155\u001b[0;31m                                   missing=missing)\n\u001b[0m\u001b[1;32m    156\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesign_info\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/statsmodels/formula/formulatools.py\u001b[0m in \u001b[0;36mhandle_formula_data\u001b[0;34m(Y, X, formula, depth, missing)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_using_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n\u001b[0;32m---> 65\u001b[0;31m                                NA_action=na_action)\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             result = dmatrices(formula, Y, depth, return_type='dataframe',\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36mdmatrices\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0meval_env\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEvalEnvironment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     (lhs, rhs) = _do_highlevel_design(formula_like, data, eval_env,\n\u001b[0;32m--> 310\u001b[0;31m                                       NA_action, return_type)\n\u001b[0m\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mPatsyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model is missing required outcome variables\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36m_do_highlevel_design\u001b[0;34m(formula_like, data, eval_env, NA_action, return_type)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     design_infos = _try_incr_builders(formula_like, data_iter_maker, eval_env,\n\u001b[0;32m--> 165\u001b[0;31m                                       NA_action)\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdesign_infos\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         return build_design_matrices(design_infos, data,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/patsy/highlevel.py\u001b[0m in \u001b[0;36m_try_incr_builders\u001b[0;34m(formula_like, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m     68\u001b[0m                                       \u001b[0mdata_iter_maker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                                       \u001b[0meval_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                                       NA_action)\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/patsy/build.py\u001b[0m in \u001b[0;36mdesign_matrix_builders\u001b[0;34m(termlists, data_iter_maker, eval_env, NA_action)\u001b[0m\n\u001b[1;32m    694\u001b[0m                                                    \u001b[0mfactor_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m                                                    \u001b[0mdata_iter_maker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m                                                    NA_action)\n\u001b[0m\u001b[1;32m    697\u001b[0m     \u001b[0;31m# Now we need the factor infos, which encapsulate the knowledge of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;31m# how to turn any given factor into a chunk of data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/patsy/build.py\u001b[0m in \u001b[0;36m_examine_factor_types\u001b[0;34m(factors, factor_states, data_iter_maker, NA_action)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_iter_maker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamine_needed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mguess_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfactor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcat_sniffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/patsy/eval.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, memorize_state, data)\u001b[0m\n\u001b[1;32m    564\u001b[0m         return self._eval(memorize_state[\"eval_code\"],\n\u001b[1;32m    565\u001b[0m                           \u001b[0mmemorize_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m                           data)\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0m__getstate__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mno_pickling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/patsy/eval.py\u001b[0m in \u001b[0;36m_eval\u001b[0;34m(self, code, memorize_state, data)\u001b[0m\n\u001b[1;32m    549\u001b[0m                                  \u001b[0mmemorize_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_env\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m                                  \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                                  inner_namespace=inner_namespace)\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmemorize_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/patsy/compat.py\u001b[0m in \u001b[0;36mcall_and_wrap_exc\u001b[0;34m(msg, origin, f, *args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m                                  origin)\n\u001b[1;32m     42\u001b[0m             \u001b[0;31m# Use 'exec' to hide this syntax from the Python 2 parser:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raise new_exc from e\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m# In python 2, we just let the original exception escape -- better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/patsy/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPatsyError\u001b[0m: Error evaluating factor: NameError: name 'Language' is not defined\n    Language ~ Task * Gender\n    ^^^^^^^^"
     ]
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "# formula = 'Language ~ Task'               # Simple regression\n",
    "formula = 'Language ~ Task * Gender'  # ANCOVA formula\n",
    "lm = ols(formula, df['PercentCorrect'])\n",
    "fit = lm.fit()\n",
    "fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
